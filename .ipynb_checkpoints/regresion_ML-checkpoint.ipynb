{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"background-color:DodgerBlue;\">Desafío - Regresión desde el aprendizaje de máquinas</h1> \n",
    "\n",
    ">\n",
    "### Descripción\n",
    ">Una consultora internacional radicada en EEUU está buscando analistas, por lo que han diseñado una prueba que permita poder seleccionar a quienes cuenten con las habilidades necesarias para crear modelación estadística. Para ello, ponen a disposición de los interesados una base de datos sobre los precios de las viviendas en Boston, utilizada en el\n",
    "paper Harrison Jr, D., & Rubinfeld, D. L. (1978). Hedonic housing prices and the demand for clean air. Journal of environmental economics and management, 5(1), 81-102.\n",
    ">\n",
    ">El objetivo del ejercicio de captación de talento es desarrollar un modelo predictivo para el valor mediano de las casas mediante el entrenamiento de un modelo de regresión lineal.\n",
    ">\n",
    ">● crim : Tasa de criminalidad por sector de Boston.\n",
    ">\n",
    ">● zn proporción de terreno residencial asignado para terrenos baldíos.\n",
    ">\n",
    ">● indus proporción de negocios no asociados al comercio por sector.\n",
    ">\n",
    ">● chas Dummy. 1 si el sector colinda con el río Charles, 0 de lo contrario.\n",
    ">\n",
    ">● nox Concentración de dióxido de carbono.\n",
    ">\n",
    ">● rm cantidad promedio de habitaciones por casa.\n",
    ">\n",
    ">● age proporción de casas construidas antes de 1940.\n",
    ">\n",
    ">● dis distancia promedio a cinco centros de empleos.\n",
    ">\n",
    ">● rad índice de accesibilidad a autopistas.\n",
    ">\n",
    ">● tax nivel de impuestos asociados a viviendas.\n",
    ">\n",
    ">● ptratio razón alumno:profesor por sector de Boston.\n",
    ">\n",
    ">● black proporción de afroamericanos por sector de Boston.\n",
    ">\n",
    ">● lstat porcentaje de población de estratos bajos.\n",
    ">\n",
    ">● medv valor mediano de las casas.\n",
    ">\n",
    "### Requerimientos\n",
    ">\n",
    ">A continuación revisaremos los requerimientos y acciones que la empresa a la cual postulas te pide realizar.\n",
    ">\n",
    ">1. Preparar el ambiente de trabajo (1 puntos)\n",
    ">\n",
    ">● Importe las librerías básicas para el análisis de datos.\n",
    ">\n",
    ">● Importe el módulo linear_model , y las funciones mean_squared_error , r2_score y train_test_split .\n",
    ">\n",
    ">● Importe la base de datos boston.csv y elimine la columna Unnamed: 0 .\n",
    ">\n",
    ">● Obtenga las medidas descriptivas de la base de datos con .describe() .\n",
    ">\n",
    ">2. Dividir la muestra (1 puntos)\n",
    ">\n",
    ">● Genere conjuntos de entrenamiento y pruebas con train_test_split .\n",
    ">\n",
    ">● Reserve un 33% de la muestra para el conjunto de pruebas.\n",
    ">\n",
    ">● Incluya una semilla pseudoaleatoria a su elección, esto lo puede hacer con el argumento random_state dentro del método train_test_plit.\n",
    ">\n",
    ">3. Generar modelos (2 puntos)\n",
    ">\n",
    ">● Ahora implementaremos dos versiones del modelo lineal:\n",
    ">\n",
    ">>○ Con intercepto.\n",
    ">>\n",
    ">>○ Sin intercepto.\n",
    ">\n",
    ">● Cada versión debe generarse en un nuevo objeto inicializado.\n",
    ">\n",
    ">● Posteriormente se deben entrenar los modelos especificando la matriz y vector de entrenamiento.\n",
    ">\n",
    ">● Con los modelos entrenados, genere una predicción de la matriz de pruebas con el método .predict().\n",
    ">\n",
    ">4. Obtención de métricas (1 puntos)\n",
    ">\n",
    ">● Ahora generaremos una función llamada report_scores que ingrese como argumentos el vector de datos predichos y el vector de datos por validar.\n",
    ">\n",
    ">● La función debe imprimir las métricas del Error Cuadrático Promedio y R2.\n",
    ">\n",
    ">● Reporte las métricas para ambos modelos. En base a ello, seleccione el mejor modelo.\n",
    ">\n",
    ">5. Refactorización del modelo (1 puntos)\n",
    ">\n",
    ">● Genere una función llamada fetch_features que ingrese como argumentos la base de datos y el nombre del vector objetivo. El nombre del vector debe ser medv por defecto.\n",
    ">\n",
    ">● La función debe retornar una lista con las correlaciones entre cada atributo y el vector objetivo y su nombre.\n",
    ">\n",
    ">● Reporte brevemente cuales son los 6 atributos con una mayor correlación absoluta con medv (de mayor a menor correlación).\n",
    ">\n",
    ">6. Refactorización del modelo predictivo (2 puntos)\n",
    ">\n",
    ">● Genere otros conjuntos de entrenamiento y validación en base a una matriz con los 6 atributos identificados en el ejercicio anterior, y el vector objetivo.\n",
    ">\n",
    ">● Entrene un modelo en base al mejor desempeño.\n",
    ">\n",
    ">● Reporte las métricas para el nuevo modelo.\n",
    ">\n",
    ">7. Predicción de casos (2 puntos): A continuación se generaron dos arrays que representan el peor escenario posible (worst_neighbor) y el mejor escenario posible (best_neighbor). Las variables representan, para cada caso, los valores de los siguientes atributos (en el mismo orden entregado): 'lstat', 'rm', 'ptratio', 'indus', 'tax', 'nox'.\n",
    ">\n",
    ">worst_neighbor = np.array([37.9, 12.6, 3.5, 27.7, 187, 0.87]).reshape(1, -1)\n",
    ">\n",
    ">best_neighbor = np.array([1.73, 22, 8.7, 0.46, 711, 0.38]).reshape(1, -1)\n",
    ">\n",
    ">● Ingrese los arrays en el modelo entrenado en el ejercicio anterior, y reporte la predicción entregada por el modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparar el ambiente de trabajo (1 puntos)\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import missingno as msno\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ● Importe la base de datos boston.csv y elimine la columna Unnamed: 0 .\n",
    "\n",
    "df = pd.read_csv('datasets/boston.csv').drop('Unnamed: 0', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio       black  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ● Obtenga las medidas descriptivas de la base de datos con .describe() .\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dividir la muestra (1 puntos)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, 'crim':'lstat'], df['medv'], test_size=.33, random_state=19137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmard\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\dmard\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Generar modelos (2 puntos)\n",
    "# ● Ahora implementaremos dos versiones del modelo lineal:\n",
    "# ○ Con intercepto.\n",
    "# ○ Sin intercepto.\n",
    "# ● Cada versión debe generarse en un nuevo objeto inicializado\n",
    "\n",
    "# Se inicializan los modelos\n",
    "modelo_1 = linear_model.LinearRegression(fit_intercept=True, normalize=True)\n",
    "modelo_2 = linear_model.LinearRegression(fit_intercept=False, normalize=False)\n",
    "\n",
    "# Se entrenan los modelos\n",
    "modelo_1.fit(X_train, y_train)\n",
    "modelo_2.fit(X_train, y_train)\n",
    "# se predice en base al conjunto de testing\n",
    "pred_modelo_1 = modelo_1.predict(X_test) # fullPrediction\n",
    "pred_modelo_2 = modelo_2.predict(X_test)# strippedPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis para el modelo Full\n",
      "Error cuadrático promedio es: 38.69173635449737\n",
      "R2 Score: 0.5661499903371137\n",
      "Análisis para el modelo desnudo\n",
      "Error cuadrático promedio es: 43.44823457034989\n",
      "R2 Score: 0.5128154287138732\n"
     ]
    }
   ],
   "source": [
    "# 4. Obtención de métricas (1 puntos)\n",
    "# ● Ahora generaremos una función llamada report_scores que ingrese como\n",
    "# argumentos el vector de datos predichos y el vector de datos por validar.\n",
    "\n",
    "def report_scores(y_test, y_predicted):\n",
    "    print(f'Error cuadrático promedio es: {mean_squared_error(y_test, y_predicted)}')\n",
    "    print(f'R2 Score: {r2_score(y_test, y_predicted)}')\n",
    "\n",
    "print('Análisis para el modelo Full')\n",
    "report_scores(y_test, pred_modelo_1)\n",
    "\n",
    "print('Análisis para el modelo desnudo')\n",
    "report_scores(y_test, pred_modelo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lstat     -0.737663\n",
       "ptratio   -0.507787\n",
       "indus     -0.483725\n",
       "tax       -0.468536\n",
       "nox       -0.427321\n",
       "crim      -0.388305\n",
       "rad       -0.381626\n",
       "age       -0.376955\n",
       "chas       0.175260\n",
       "dis        0.249929\n",
       "black      0.333461\n",
       "zn         0.360445\n",
       "rm         0.695360\n",
       "medv       1.000000\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Refactorización del modelo (1 puntos)\n",
    "# ● Genere una función llamada fetch_features que ingrese como argumentos la\n",
    "# base de datos y el nombre del vector objetivo. El nombre del vector debe ser\n",
    "# medv por defecto.\n",
    "\n",
    "def fetch_features(df, colName = 'medv'):\n",
    "    return df.corr()[colName]\n",
    "fetch_features(df).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fetch_features(df, 'medv').sort_values('abs_cors', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático promedio es: 36.996117983127945\n",
      "R2 Score: 0.5817287367224555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmard\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 6. Refactorización del modelo predictivo (2 puntos)\n",
    "#● Genere otros conjuntos de entrenamiento y validación en base a una matriz con\n",
    "# los 6 atributos identificados en el ejercicio anterior, y el vector objetivo.\n",
    "\n",
    "\n",
    "# se Recrean los conjuntos de entrenamiento y validación\n",
    "X_train_dep, X_test_dep, y_train_dep, y_test_dep = train_test_split(df.loc[:, ['lstat', 'ptratio', 'rm', 'indus', 'tax', 'nox']], df['medv'], test_size=.33, random_state=15820)\n",
    "# se entrena el modelo\n",
    "depuratedModel = linear_model.LinearRegression(fit_intercept=True, normalize=True)\n",
    "depuratedModel.fit(X_train_dep, y_train_dep)\n",
    "# se reportan las metricas\n",
    "report_scores(y_test_dep, depuratedModel.predict(X_test_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Predicción de casos (2 puntos):\n",
    "\n",
    "# Peor ecenario\n",
    "worst_neighbor = np.array([37.9, 12.6, 3.5, 27.7, 187, 0.87]).reshape(1, -1)\n",
    "# Mwjor ecenario\n",
    "best_neighbor = np.array([1.73, 22, 8.7, 0.46, 711, 0.38]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediccion para el peor ecenario [1.40169401]\n",
      "Prediccion para el mejor ecenario [35.30936634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmard\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\dmard\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# predicciones\n",
    "print(f'Prediccion para el peor ecenario {depuratedModel.predict(worst_neighbor)}')\n",
    "print(f'Prediccion para el mejor ecenario {depuratedModel.predict(best_neighbor)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fe23d4cdea1a1fdeea398f38169f58ea6e36b10f84ee4017a8f0fee693ee786"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
